{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2d4fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n",
    "from torch import nn\n",
    "conv_arch = ((1, 64), (1, 128), (1, 256), (1, 512), (1, 512))\n",
    "\n",
    "def vgg_block(num_convs,in_channels,out_channels):\n",
    "    layers=[]\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_channels=out_channels\n",
    "    layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50528b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(conv_arch):\n",
    "    conv_blks=[]\n",
    "    in_channels=1\n",
    "    for (num_convs,out_channels) in conv_arch:\n",
    "        conv_blks.append(vgg_block(num_convs,in_channels,out_channels))\n",
    "        in_channels=out_channels\n",
    "    return nn.Sequential(*conv_blks, nn.Flatten(),nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5),nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),nn.Linear(4096, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cea74ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 4\n",
    "small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]\n",
    "model = vgg(small_conv_arch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f54312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\csrgzn\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    transform = [transforms.ToTensor(),transforms.Normalize((0.1307, ), (0.3081, ))]\n",
    "    if resize:\n",
    "        transform.insert(0, transforms.Resize(resize))\n",
    "    transform = transforms.Compose(transform)\n",
    "\n",
    "    mnist_train = datasets.FashionMNIST(\n",
    "        root=\"../data\", train=True, transform=transform, download=True)\n",
    "    mnist_test = datasets.FashionMNIST(\n",
    "        root=\"../data\", train=False, transform=transform, download=True)\n",
    "    return (data.DataLoader(mnist_train, batch_size, shuffle=True),data.DataLoader(mnist_test, batch_size, shuffle=False))\n",
    "# design model using class\n",
    " \n",
    "train_loader,test_loader= load_data_fashion_mnist(batch_size, resize=244)\n",
    "\n",
    "# construct loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    " \n",
    "\n",
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, data in enumerate(train_loader, 0):\n",
    "        # 获得一个批次的数据和标签\n",
    "        inputs, target = data\n",
    "        optimizer.zero_grad()\n",
    "        # 获得模型预测结果(64, 10)\n",
    "        outputs = model(inputs)\n",
    "        # 交叉熵代价函数outputs(64,10),target（64）\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % 300 == 299:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, batch_idx+1, running_loss/300))\n",
    "            running_loss = 0.0\n",
    " \n",
    " \n",
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, dim=1) # dim = 1 列是第0个维度，行是第1个维度\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item() # 张量之间的比较运算\n",
    "    print('accuracy on test set: %d %% ' % (100*correct/total))\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    for epoch in range(10):\n",
    "        train(epoch)\n",
    "        test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672e3e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
